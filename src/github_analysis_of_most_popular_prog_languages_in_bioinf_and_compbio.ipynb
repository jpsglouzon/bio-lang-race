{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7a0cbde-1e67-48be-85f3-16e3b71dfac3",
   "metadata": {},
   "source": [
    "# Most popular programming languages in Bioinformatics and Computational Biology -- Github\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f3f2225-4f46-43cb-8553-18954a2d0132",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from datetime import datetime\n",
    "from tabulate import tabulate\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7647708d-9623-4c29-9dea-6b92ee96b43c",
   "metadata": {},
   "source": [
    "## Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92cdc676-86d8-48f5-80a5-1640b3186c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primary input\n",
    "topic='bioinformatics'\n",
    "github_token = ''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69f2993c-09fe-4af5-a55b-fdb297e6ccd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Secondary input\n",
    "# Parameters\n",
    "min_stars = 10\n",
    "max_stars = 5000 # why? repo with the most stars and associated with programming language is biopython with 4.8k stars\n",
    "list_years=list(range(2008,2026)) # For each year the 100 most starred repo are retrieved; The limit of results per search is 100; retrieving all results require pagination management\n",
    "keywords=''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f64ae3-20da-490a-9033-b0e504856b55",
   "metadata": {},
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e828b8e-fcae-4495-b569-f806aa97e6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stats_repo_pl_vs_topic_df='./results/programming_language_x_'+topic+'.csv'\n",
    "bar_chat_pl_vs_topic_video='./results/programming_language_x_'+topic+'.mp4'\n",
    "\n",
    "stats_repo_topics_vs_topic_df='./results/topics_x_'+topic+'.csv'\n",
    "bar_chat_topics_vs_topic_video='./results/topics_x_'+topic+'.mp4'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378a940e-ce7c-4bb1-88fc-703a2ec95edd",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04549476-0311-4c67-9509-a101ccadfe70",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "635a3031-bdd1-4917-9090-7904766d0415",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def search_github_repos(keywords, topic,min_stars, max_stars, start_date, end_date, token=None):\n",
    "    \n",
    "    # Build the query\n",
    "    keywords_query = ' '.join(keywords)\n",
    "    stars_query = f\"stars:{min_stars}..{max_stars}\"\n",
    "    date_query = f\"pushed:{start_date}..{end_date}\"\n",
    "    topic_query = f\"topic:{topic}\"\n",
    "    \n",
    "    query = f\"{keywords_query} {stars_query} {date_query} {topic_query} \"\n",
    "    \n",
    "    # GitHub API endpoint\n",
    "    url = \"https://api.github.com/search/repositories\"\n",
    "    \n",
    "    # Headers\n",
    "    headers = {\n",
    "        \"Accept\": \"application/vnd.github.v3+json\"\n",
    "    }\n",
    "    \n",
    "    if token:\n",
    "        headers[\"Authorization\"] = f\"token {token}\"\n",
    "    \n",
    "    # Parameters\n",
    "    params = {\n",
    "        \"q\": query,\n",
    "        \"sort\": \"stars\",\n",
    "        \"order\": \"desc\",\n",
    "        \"per_page\": 100  # Max results per page\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, params=params)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        data = response.json()\n",
    "        \n",
    "        # Extract repository information\n",
    "        repos = []\n",
    "        for item in data.get('items', []):\n",
    "            repo_info = {\n",
    "                'name': item['full_name'],\n",
    "                'stars': int(item['stargazers_count']),\n",
    "                'created': datetime.strptime(item['created_at'], '%Y-%m-%dT%H:%M:%SZ').strftime('%Y-%m-%d'),\n",
    "                'forks': int(item['forks_count']),\n",
    "                'topics': item['topics'],\n",
    "                'language': item['language'],\n",
    "                'languages_url': item['languages_url'],\n",
    "                'selected_year': int(start_date.split('-')[0])\n",
    "\n",
    "            }\n",
    "            repos.append(repo_info)\n",
    "                    \n",
    "        return repos, data.get('total_count', 0)\n",
    "    \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return [], 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49af9e2e-255b-4da3-8ce6-36856cda75c6",
   "metadata": {},
   "source": [
    "### Get Stats From Github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "489bb531-24ea-46ae-b763-3de029ba8a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for repositories\n",
      "Stars range: 10 - 5000\n",
      "Date range: 2008-01-01 to 2008-12-31\n",
      "Topic: bioinformatics\n",
      "Total: 0\n",
      "Searching for repositories\n",
      "Stars range: 10 - 5000\n",
      "Date range: 2009-01-01 to 2009-12-31\n",
      "Topic: bioinformatics\n",
      "Total: 0\n",
      "Searching for repositories\n",
      "Stars range: 10 - 5000\n",
      "Date range: 2010-01-01 to 2010-12-31\n",
      "Topic: bioinformatics\n",
      "Total: 0\n",
      "Searching for repositories\n",
      "Stars range: 10 - 5000\n",
      "Date range: 2011-01-01 to 2011-12-31\n",
      "Topic: bioinformatics\n",
      "Total: 0\n",
      "Searching for repositories\n",
      "Stars range: 10 - 5000\n",
      "Date range: 2012-01-01 to 2012-12-31\n",
      "Topic: bioinformatics\n",
      "Total: 0\n",
      "Searching for repositories\n",
      "Stars range: 10 - 5000\n",
      "Date range: 2013-01-01 to 2013-12-31\n",
      "Topic: bioinformatics\n",
      "Total: 2\n",
      "Searching for repositories\n",
      "Stars range: 10 - 5000\n",
      "Date range: 2014-01-01 to 2014-12-31\n",
      "Topic: bioinformatics\n",
      "Total: 0\n",
      "Searching for repositories\n",
      "Stars range: 10 - 5000\n",
      "Date range: 2015-01-01 to 2015-12-31\n",
      "Topic: bioinformatics\n",
      "Total: 0\n",
      "Searching for repositories\n",
      "Stars range: 10 - 5000\n",
      "Date range: 2016-01-01 to 2016-12-31\n",
      "Topic: bioinformatics\n",
      "Total: 8\n",
      "Searching for repositories\n",
      "Stars range: 10 - 5000\n",
      "Date range: 2017-01-01 to 2017-12-31\n",
      "Topic: bioinformatics\n",
      "Error: 403 Client Error: rate limit exceeded for url: https://api.github.com/search/repositories?q=+stars%3A10..5000+pushed%3A2017-01-01..2017-12-31+topic%3Abioinformatics+&sort=stars&order=desc&per_page=100\n",
      "Total: 0\n",
      "Searching for repositories\n",
      "Stars range: 10 - 5000\n",
      "Date range: 2018-01-01 to 2018-12-31\n",
      "Topic: bioinformatics\n",
      "Error: 403 Client Error: rate limit exceeded for url: https://api.github.com/search/repositories?q=+stars%3A10..5000+pushed%3A2018-01-01..2018-12-31+topic%3Abioinformatics+&sort=stars&order=desc&per_page=100\n",
      "Total: 0\n",
      "Searching for repositories\n",
      "Stars range: 10 - 5000\n",
      "Date range: 2019-01-01 to 2019-12-31\n",
      "Topic: bioinformatics\n",
      "Error: 403 Client Error: rate limit exceeded for url: https://api.github.com/search/repositories?q=+stars%3A10..5000+pushed%3A2019-01-01..2019-12-31+topic%3Abioinformatics+&sort=stars&order=desc&per_page=100\n",
      "Total: 0\n",
      "Searching for repositories\n",
      "Stars range: 10 - 5000\n",
      "Date range: 2020-01-01 to 2020-12-31\n",
      "Topic: bioinformatics\n",
      "Error: 403 Client Error: rate limit exceeded for url: https://api.github.com/search/repositories?q=+stars%3A10..5000+pushed%3A2020-01-01..2020-12-31+topic%3Abioinformatics+&sort=stars&order=desc&per_page=100\n",
      "Total: 0\n",
      "Searching for repositories\n",
      "Stars range: 10 - 5000\n",
      "Date range: 2021-01-01 to 2021-12-31\n",
      "Topic: bioinformatics\n",
      "Error: 403 Client Error: rate limit exceeded for url: https://api.github.com/search/repositories?q=+stars%3A10..5000+pushed%3A2021-01-01..2021-12-31+topic%3Abioinformatics+&sort=stars&order=desc&per_page=100\n",
      "Total: 0\n",
      "Searching for repositories\n",
      "Stars range: 10 - 5000\n",
      "Date range: 2022-01-01 to 2022-12-31\n",
      "Topic: bioinformatics\n",
      "Error: 403 Client Error: rate limit exceeded for url: https://api.github.com/search/repositories?q=+stars%3A10..5000+pushed%3A2022-01-01..2022-12-31+topic%3Abioinformatics+&sort=stars&order=desc&per_page=100\n",
      "Total: 0\n",
      "Searching for repositories\n",
      "Stars range: 10 - 5000\n",
      "Date range: 2023-01-01 to 2023-12-31\n",
      "Topic: bioinformatics\n",
      "Error: 403 Client Error: rate limit exceeded for url: https://api.github.com/search/repositories?q=+stars%3A10..5000+pushed%3A2023-01-01..2023-12-31+topic%3Abioinformatics+&sort=stars&order=desc&per_page=100\n",
      "Total: 0\n",
      "Searching for repositories\n",
      "Stars range: 10 - 5000\n",
      "Date range: 2024-01-01 to 2024-12-31\n",
      "Topic: bioinformatics\n",
      "Error: 403 Client Error: rate limit exceeded for url: https://api.github.com/search/repositories?q=+stars%3A10..5000+pushed%3A2024-01-01..2024-12-31+topic%3Abioinformatics+&sort=stars&order=desc&per_page=100\n",
      "Total: 0\n",
      "Searching for repositories\n",
      "Stars range: 10 - 5000\n",
      "Date range: 2025-01-01 to 2025-12-31\n",
      "Topic: bioinformatics\n",
      "Error: 403 Client Error: rate limit exceeded for url: https://api.github.com/search/repositories?q=+stars%3A10..5000+pushed%3A2025-01-01..2025-12-31+topic%3Abioinformatics+&sort=stars&order=desc&per_page=100\n",
      "Total: 0\n"
     ]
    }
   ],
   "source": [
    "all_selected_repos=[]\n",
    "list_total_results=[]\n",
    "\n",
    "for year in list_years:\n",
    "    \n",
    "    start_date = str(year)+'-01-01'\n",
    "    end_date = str(year)+'-12-31'\n",
    "\n",
    "\n",
    "    print(f\"Searching for repositories\")\n",
    "    print(f\"Stars range: {min_stars} - {max_stars}\")\n",
    "    print(f\"Date range: {start_date} to {end_date}\")\n",
    "    print(f\"Topic: {topic}\")\n",
    "\n",
    "    repos, total = search_github_repos(\n",
    "        keywords=keywords,\n",
    "        topic=topic,\n",
    "        min_stars=min_stars,\n",
    "        max_stars=max_stars,\n",
    "        start_date=start_date,\n",
    "        end_date=end_date,\n",
    "        token=github_token\n",
    "    )\n",
    "\n",
    "    print(f\"Total: {total}\")\n",
    "    \n",
    "    list_total_results.append(total)\n",
    "\n",
    "    all_selected_repos=all_selected_repos+repos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52d83e0c-f43b-4720-8764-c3fdd7f080c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "                                                name  stars     created  \\\n",
      "0                                          lh3/fermi     75  2012-01-06   \n",
      "1                 mpieva/mapping-iterative-assembler     19  2012-07-02   \n",
      "2                                        bio4j/bio4j    120  2011-01-31   \n",
      "3                                            lh3/bfc     74  2014-12-30   \n",
      "4                                  shenwei356/go4bio     31  2016-08-15   \n",
      "5                                     seandavi/ngCGH     18  2011-02-25   \n",
      "6                                ChillarAnand/fadapa     16  2014-10-16   \n",
      "7  drewwiens/TensorFlow-DNNs-for-Predicting-DNA-T...     15  2016-12-01   \n",
      "8                                  shenwei356/gtaxon     14  2016-02-13   \n",
      "9                                   mikessh/oncofuse     12  2014-06-24   \n",
      "\n",
      "   forks                                             topics          language  \\\n",
      "0     15        [bioinformatics, denovo-assembly, genomics]                 C   \n",
      "1      7  [alignment, bioinformatics, consensus-calling,...                 C   \n",
      "2     19  [bio4j, bio4j-titan, bioinformatics, database,...              Java   \n",
      "3     12                         [bioinformatics, genomics]               TeX   \n",
      "4      5                           [bioinformatics, golang]              None   \n",
      "5      9  [bioinformatics, cancer-genomics, genomics, py...            Python   \n",
      "6     11                   [bioinformatics, fastqc, python]  Jupyter Notebook   \n",
      "7      7  [bioinformatics, deep-neural-networks, dna-seq...            Python   \n",
      "8      2  [bioinformatics, client, golang, lca, restful,...                Go   \n",
      "9      4                  [bioinformatics, fusion, rna-seq]            Groovy   \n",
      "\n",
      "                                       languages_url  selected_year  \n",
      "0   https://api.github.com/repos/lh3/fermi/languages           2013  \n",
      "1  https://api.github.com/repos/mpieva/mapping-it...           2013  \n",
      "2  https://api.github.com/repos/bio4j/bio4j/langu...           2016  \n",
      "3     https://api.github.com/repos/lh3/bfc/languages           2016  \n",
      "4  https://api.github.com/repos/shenwei356/go4bio...           2016  \n",
      "5  https://api.github.com/repos/seandavi/ngCGH/la...           2016  \n",
      "6  https://api.github.com/repos/ChillarAnand/fada...           2016  \n",
      "7  https://api.github.com/repos/drewwiens/TensorF...           2016  \n",
      "8  https://api.github.com/repos/shenwei356/gtaxon...           2016  \n",
      "9  https://api.github.com/repos/mikessh/oncofuse/...           2016  \n"
     ]
    }
   ],
   "source": [
    "print(len(all_selected_repos))\n",
    "df = pd.DataFrame(all_selected_repos).reset_index(drop=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55594ab-29bf-4c71-9494-bb8b584cd3ec",
   "metadata": {},
   "source": [
    "### Parse and format stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d0509d7-fd47-405a-aead-a62956b2871b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    year  stars          language\n",
      "0   2013     94                 C\n",
      "1   2016     94                 C\n",
      "2   2013      0                Go\n",
      "3   2016     14                Go\n",
      "4   2013      0            Groovy\n",
      "5   2016     12            Groovy\n",
      "6   2013      0              Java\n",
      "7   2016    120              Java\n",
      "8   2013      0  Jupyter Notebook\n",
      "9   2016     16  Jupyter Notebook\n",
      "10  2013      0            Python\n",
      "11  2016     33            Python\n",
      "12  2013      0               TeX\n",
      "13  2016     74               TeX\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: 'results'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 26>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m df_stats_raw \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(stats_raw)\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(df_stats_raw)\n\u001b[0;32m---> 26\u001b[0m \u001b[43mdf_stats_raw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstats_repo_pl_vs_topic_df\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/generic.py:3551\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3540\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[1;32m   3542\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[1;32m   3543\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[1;32m   3544\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3548\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[1;32m   3549\u001b[0m )\n\u001b[0;32m-> 3551\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3552\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3553\u001b[0m \u001b[43m    \u001b[49m\u001b[43mline_terminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mline_terminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3554\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3555\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3556\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3557\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3558\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3559\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3560\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3561\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3562\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3563\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3564\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3565\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3566\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3567\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3568\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/io/formats/format.py:1180\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m   1159\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1161\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[1;32m   1162\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[1;32m   1163\u001b[0m     line_terminator\u001b[38;5;241m=\u001b[39mline_terminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[1;32m   1179\u001b[0m )\n\u001b[0;32m-> 1180\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[1;32m   1183\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/io/formats/csvs.py:241\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[0;32m--> 241\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[1;32m    249\u001b[0m \n\u001b[1;32m    250\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[1;32m    252\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[1;32m    253\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mline_terminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    258\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[1;32m    259\u001b[0m     )\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/io/common.py:697\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    695\u001b[0m \u001b[38;5;66;03m# Only for write methods\u001b[39;00m\n\u001b[1;32m    696\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m is_path:\n\u001b[0;32m--> 697\u001b[0m     \u001b[43mcheck_parent_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compression:\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzstd\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    701\u001b[0m         \u001b[38;5;66;03m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/io/common.py:571\u001b[0m, in \u001b[0;36mcheck_parent_directory\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    569\u001b[0m parent \u001b[38;5;241m=\u001b[39m Path(path)\u001b[38;5;241m.\u001b[39mparent\n\u001b[1;32m    570\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parent\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[0;32m--> 571\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot save file into a non-existent directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mOSError\u001b[0m: Cannot save file into a non-existent directory: 'results'"
     ]
    }
   ],
   "source": [
    "df_na_removed=df.dropna().reset_index(drop=True)\n",
    "\n",
    "list_selected_year=list(np.unique(df_na_removed['selected_year']))\n",
    "list_language=list(np.unique(df_na_removed['language']))\n",
    "\n",
    "stats_raw=[]\n",
    "\n",
    "for lang in list_language:\n",
    "\n",
    "    total_count_start_per_year_per_language=0\n",
    "    \n",
    "    for year in list_selected_year:\n",
    "\n",
    "        count_start_per_year_per_language=df_na_removed[(df_na_removed['selected_year'] == year) & (df_na_removed['language'] == lang)]['stars'].sum()\n",
    "        total_count_start_per_year_per_language=total_count_start_per_year_per_language+count_start_per_year_per_language\n",
    "        stat_info = {\n",
    "            'year': year,\n",
    "            'stars': total_count_start_per_year_per_language,\n",
    "            'language': lang\n",
    "        }\n",
    "        stats_raw.append(stat_info)\n",
    "\n",
    "df_stats_raw = pd.DataFrame(stats_raw).reset_index(drop=True)\n",
    "print(df_stats_raw)\n",
    "\n",
    "df_stats_raw.to_csv(stats_repo_pl_vs_topic_df) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c77bf14-b78d-4bfd-bf98-8515bb9f0878",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_repo_pl_vs_topic_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfee6add-bf57-4c79-bb00-aa7d41d3d75b",
   "metadata": {},
   "source": [
    "### Compute and Save Vid√©o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0515683e-12d9-4438-bfbc-bdb899302e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bar_chart_race as bcr\n",
    "import matplotlib\n",
    "# Set the path to your ffmpeg executable\n",
    "# Replace '/usr/bin/ffmpeg' with your actual path, e.g., 'C:\\\\ffmpeg\\\\bin\\\\ffmpeg.exe' on Windows\n",
    "matplotlib.rcParams['animation.ffmpeg_path'] = '/usr/bin/ffmpeg' \n",
    "\n",
    "df_stats_raw = df_stats_raw.sort_values(by='year')\n",
    "\n",
    "df_stats_raw['year_string'] = [datetime.strptime(str(item)+'-01-01', \"%Y-%m-%d\") for item in list(df_stats_raw['year']) ]\n",
    "df_wide = df_stats_raw.pivot(index='year_string', columns='language', values='stars')\n",
    "df_wide.index.name='date'\n",
    "\n",
    "bcr_fig=bcr.bar_chart_race(df_wide,  \n",
    "                   filename=bar_chat_pl_vs_topic_video,\n",
    "                   perpendicular_bar_func='mean', n_bars=10,\n",
    "                   \n",
    "                    title={\n",
    "                        'label':'Most popular (most starred) programming languages in ' + topic+ ' from 2013 to 2025',\n",
    "                        'size': 12,\n",
    "                    },\n",
    "                   shared_fontdict={'family': 'Helvetica', 'weight': 'bold',\n",
    "                                    'color': 'rebeccapurple'}, \n",
    "                   interpolate_period=False,\n",
    "                    period_template='%Y',\n",
    "                   period_length=1100,\n",
    "                fig_kwargs =\n",
    "                    {\n",
    "                        'figsize': (10, 5),\n",
    "                        'dpi': 120,\n",
    "                    }\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d897faac-3194-4cf1-8c95-541481404b6d",
   "metadata": {},
   "source": [
    "## Topics related to topic of refence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687a0dee-9760-4330-b6c6-2886ebdd3078",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "df_na_removed=df.dropna().reset_index(drop=True)\n",
    "\n",
    "list_selected_year=list(np.unique(df_na_removed['selected_year']))\n",
    "list_topics = [item for sublist in list(df_na_removed['topics']) for item in sublist]\n",
    "list_topics=list(np.unique(list_topics))\n",
    "# remove topic of refence\n",
    "list_topics.remove(topic)\n",
    "list_topics.remove('python')\n",
    "\n",
    "stats_topic_raw=[]\n",
    "\n",
    "for topic_current in list_topics:\n",
    "    total_count_start_per_year_per_topic=0\n",
    "    \n",
    "    for year in list_selected_year:\n",
    "        \n",
    "        list_tf_matching_topic_current = [True if topic_current in current_list_topic else False for current_list_topic in df_na_removed['topics']]\n",
    "\n",
    "        count_start_per_year_per_topic=df_na_removed[(df_na_removed['selected_year'] == year) & list_tf_matching_topic_current]['stars'].sum()\n",
    "        total_count_start_per_year_per_topic=total_count_start_per_year_per_topic+count_start_per_year_per_topic\n",
    "        stat_info = {\n",
    "            'year': year,\n",
    "            'stars': total_count_start_per_year_per_topic,\n",
    "            'topic': topic_current\n",
    "        }\n",
    "        stats_topic_raw.append(stat_info)\n",
    "\n",
    "df_stats_topic_raw = pd.DataFrame(stats_topic_raw).reset_index(drop=True)\n",
    "print(df_stats_topic_raw)\n",
    "\n",
    "df_stats_topic_raw.to_csv(stats_repo_topics_vs_topic_df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c808d3-62b7-4fb5-8fdf-9120ade63b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bar_chart_race as bcr\n",
    "import matplotlib\n",
    "# Set the path to your ffmpeg executable\n",
    "# Replace '/usr/bin/ffmpeg' with your actual path, e.g., 'C:\\\\ffmpeg\\\\bin\\\\ffmpeg.exe' on Windows\n",
    "matplotlib.rcParams['animation.ffmpeg_path'] = '/usr/bin/ffmpeg' \n",
    "\n",
    "df_stats_topic_raw = df_stats_topic_raw.sort_values(by='year')\n",
    "\n",
    "df_stats_topic_raw['year_string'] = [datetime.strptime(str(item)+'-01-01', \"%Y-%m-%d\") for item in list(df_stats_topic_raw['year']) ]\n",
    "df_stats_topic_wide = df_stats_topic_raw.pivot(index='year_string', columns='topic', values='stars')\n",
    "df_stats_topic_wide.index.name='date'\n",
    "\n",
    "bcr_fig=bcr.bar_chart_race(df_stats_topic_wide,  \n",
    "                   filename=bar_chat_topics_vs_topic_video,\n",
    "                   perpendicular_bar_func='mean', n_bars=10,                   \n",
    "                    title={\n",
    "                        'label':'Topics strongly associated with ' + topic + ' from 2008 to 2025',\n",
    "                        'size': 12,\n",
    "                    },\n",
    "                   shared_fontdict={'family': 'Helvetica', 'weight': 'bold',\n",
    "                                    'color': 'rebeccapurple'}, \n",
    "                   interpolate_period=False,\n",
    "                    period_template='%Y',\n",
    "                   period_length=1100,\n",
    "                )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d768a2-d235-430a-93fd-954d30270401",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fc0153-7237-470e-9c91-bd6d66c2d1c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
